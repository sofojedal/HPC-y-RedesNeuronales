{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "109ab491"
      },
      "source": [
        "# Taller 2: Métricas de Desempeño\n",
        "---\n",
        "\n",
        "Este taller busca evaluar conceptos de modelamiento y la implementación de métricas de desempeño para la evaluación de modelos de Machine Learning supervisados.\n",
        "\n",
        "Librerías:"
      ],
      "id": "109ab491"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "227aa92d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import optimize\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score\n",
        "from numpy.typing import ArrayLike\n",
        "from typing import Tuple\n",
        "from IPython.display import display\n",
        "import seaborn as sns"
      ],
      "id": "227aa92d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef23fc9b"
      },
      "source": [
        "## **1. Carga de Datos**\n",
        "---\n",
        "\n",
        "En este caso trabajáremos con el conjunto de datos [Heart Attack Analysis & Prediction Dataset](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset?select=heart.csv) de Kaggle, vamos a descargarlo:"
      ],
      "id": "ef23fc9b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa48bcec",
        "outputId": "d81feb1f-aef7-4edb-cfff-e5396fc5957f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-24 13:07:54--  https://drive.google.com/uc?export=view&id=1djX2CPMY-O_vskg9ey326auY8Yho415v\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.204.138, 74.125.204.100, 74.125.204.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.204.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-4g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/8526sjo83eu0kpmqi7mgekaiebt7ftj7/1682341650000/16848862265445619282/*/1djX2CPMY-O_vskg9ey326auY8Yho415v?e=view&uuid=b1065e73-67c5-438f-be63-86640665183f [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-24 13:07:55--  https://doc-10-4g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/8526sjo83eu0kpmqi7mgekaiebt7ftj7/1682341650000/16848862265445619282/*/1djX2CPMY-O_vskg9ey326auY8Yho415v?e=view&uuid=b1065e73-67c5-438f-be63-86640665183f\n",
            "Resolving doc-10-4g-docs.googleusercontent.com (doc-10-4g-docs.googleusercontent.com)... 64.233.188.132, 2404:6800:4008:c06::84\n",
            "Connecting to doc-10-4g-docs.googleusercontent.com (doc-10-4g-docs.googleusercontent.com)|64.233.188.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4209 (4.1K) [application/zip]\n",
            "Saving to: ‘heart_failure.zip’\n",
            "\n",
            "heart_failure.zip   100%[===================>]   4.11K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-24 13:07:55 (39.6 MB/s) - ‘heart_failure.zip’ saved [4209/4209]\n",
            "\n",
            "Archive:  heart_failure.zip\n",
            "replace heart.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget 'https://drive.google.com/uc?export=view&id=1djX2CPMY-O_vskg9ey326auY8Yho415v' -O heart_failure.zip\n",
        "!unzip heart_failure.zip"
      ],
      "id": "fa48bcec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3485302f"
      },
      "source": [
        "Cargamos el conjunto de datos:"
      ],
      "id": "3485302f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba397770"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"heart.csv\")\n",
        "display(data.head())"
      ],
      "id": "ba397770"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f15f04a3"
      },
      "source": [
        "## **2. Análisis Exploratorio**\n",
        "---\n",
        "\n",
        "En este punto deberá explorar y entender el conjunto de datos y sus elementos.\n",
        "\n",
        "- ¿Cuántas columnas tiene el conjunto de datos, qué significa cada una?"
      ],
      "id": "f15f04a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19630b61"
      },
      "source": [
        "**INGRESE SU RESPUESTA ACÁ**\n",
        "\n",
        "**Respuesta =** En la base de datos tenemos un total de 14 columnas, las cuales incluyen información del paciente como **age:** que corresponde a la edad del paciente, **sex:** sexo del paciente, **cp:** que identifica el tipo del dolor torácico, tenemos 4, angina típica, angina atípica, dolor no aginoso y dolor asintomático. Por otro lado tenemos **trtbps:** el cual es la presión arterial en reposo, este se mide en mm y Hg, **chol:** que coincide con el coresterol por BMI en mg/dl, **fbs:** variable que se ajusta al azucar en la sangre en ayunas, este se mide en 120 mg/dl, si este cumple retornará 1, si no lo hace, este retornará 0. **rest_ecg:** son basicamente los resultados electrocardiográficos en reposo, este retornará 0 si esta en estado normal, pero si ste presenta problemas en la onda ST-T retornará 1, así mismo retornará 2 para mostrar la hipertrofia ventricular izquierda probable o definida a partir de los criterios de estres. Tenemos **thalach:** la cual respresenta la frecuencia cárdiaca máxima alcanzada, así mismo esta **exng:** variable que responde a la angina inducida por el ejercicio, **oldpeak:** es una medida del descenso del segmento ST después del ejercicio en relación con el nivel de reposo. Es un indicador de la gravedad de la enfermedad cardíaca, **slp:** es una variable categórica que describe la pendiente del segmento ST en el pico del ejercicio, **caa:** es una variable categórica que indica el número de vasos principales coloreados por flourosopía, **thal:** es una variable categórica que indica el resultado del estrés cardíaco según la escala de Thal, **output:** es una variable categórica binaria que indica la presencia o ausencia de enfermedad cardíaca."
      ],
      "id": "19630b61"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1NG4KRWQGJp"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ],
      "id": "A1NG4KRWQGJp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e60fbbd1"
      },
      "source": [
        "Implemente una función que permita determinar si una columna es continúa o categórica (puede guiarse por el número de elementos únicos que tenga cada columna):"
      ],
      "id": "e60fbbd1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71339b3c"
      },
      "outputs": [],
      "source": [
        "def continuous_or_categoric(data: pd.DataFrame, column: str) -> bool:\n",
        "\n",
        "    # Comprueba si la columna es de tipo \"Object\" o \"boolean\".\n",
        "    if data[column].dtype in ['object', 'bool']:\n",
        "        return False\n",
        "\n",
        "    # Validar si la columna está clasificada como \"datetime\".\n",
        "    if pd.api.types.is_datetime64_any_dtype(data[column].dtype):\n",
        "        return True\n",
        "\n",
        "    # Asegurarse de que la columna tenga el tipo de datos \"integer\" o \"float\".\n",
        "    if pd.api.types.is_numeric_dtype(data[column].dtype):\n",
        "        # Verificar si la columna tiene una cardinalidad (número de valores distintos) menor a 20.\n",
        "        if data[column].nunique() <= 20:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "    # En situaciones donde no se pueda determinar el tipo de la columna, devolver \"desconocida\".\n",
        "    return 'desconocida'"
      ],
      "id": "71339b3c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58c60a4a"
      },
      "source": [
        "Use la siguiente celda para probar su código (puede cambiar el nombre de la variable)."
      ],
      "id": "58c60a4a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e999f1f4"
      },
      "outputs": [],
      "source": [
        "display(continuous_or_categoric(data, \"age\"))"
      ],
      "id": "e999f1f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d0835d1"
      },
      "source": [
        "- ¿Cómo es la distribución de las columnas?\n",
        "\n",
        "Para esto debe implementar la función `show_distribution` la cual debe graficar un diagrama de tipo [kernel density estimation](https://seaborn.pydata.org/generated/seaborn.kdeplot.html) para las variables continuas y un diagrama de barras para las variables categóricas:"
      ],
      "id": "1d0835d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz9S_CODoWjU"
      },
      "outputs": [],
      "source": [
        "def show_distribution(data: pd.DataFrame, column: str) -> plt.Figure:\n",
        "    if continuous_or_categoric(data, column) == 'desconocida':\n",
        "        raise ValueError(f'Tipo de datos desconocido para la columna {column}.')\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    if continuous_or_categoric(data, column):\n",
        "        sns.kdeplot(data=data, x=column, ax=ax)\n",
        "    else:\n",
        "        sns.countplot(data=data, x=column, ax=ax)\n",
        "\n",
        "    return fig"
      ],
      "id": "zz9S_CODoWjU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "307bb6f4"
      },
      "source": [
        "Utilice la siguiente celda para probar su código:"
      ],
      "id": "307bb6f4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3caa60bb"
      },
      "outputs": [],
      "source": [
        "fig = show_distribution(data, \"age\")\n",
        "fig.show()"
      ],
      "id": "3caa60bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37d815c1"
      },
      "source": [
        "- ¿Cuáles son las variables independientes y cuál es la variable dependiente?\n",
        "\n",
        "Para esto debe implementar la función `target_variable` la cual debe separar las columnas que se tomarán como variables independientes de la columna objetivo."
      ],
      "id": "37d815c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fb2a3a6"
      },
      "outputs": [],
      "source": [
        "def target_variable(data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "\n",
        "    features, labels = data.iloc[:, :-1], data.iloc[:, -1]\n",
        "    return features, labels"
      ],
      "id": "9fb2a3a6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0896a7e"
      },
      "source": [
        "Utilice la siguiente celda para probar su código:"
      ],
      "id": "f0896a7e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6da58d2"
      },
      "outputs": [],
      "source": [
        "features, labels = target_variable(data)"
      ],
      "id": "c6da58d2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c837777c"
      },
      "source": [
        "## **3. Preprocesamiento**\n",
        "---\n",
        "\n",
        "En este punto debe implementar una función para preprocesar el conjunto de datos. debe aplicar una transformación de tipo `min_max` sobre los datos (cada columna debe estar entre 0 y 1):\n",
        "\n",
        "$$\n",
        "x_{minmax} = \\frac{x - \\text{min}(x)}{\\text{max}(x) - \\text{min}(x)}\n",
        "$$\n",
        "\n",
        "Puede utilizar la clase `MinMaxScaler` de `sklearn`. Adicionalmente, debe convertir las etiquetas a un arreglo de `numpy`."
      ],
      "id": "c837777c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d96d430c"
      },
      "outputs": [],
      "source": [
        "def preprocess(features: pd.DataFrame, labels: pd.Series) -> Tuple[ArrayLike, ArrayLike]:\n",
        "\n",
        "    # MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    features_p, labels_p = scaler.fit_transform(features), np.array(labels)\n",
        "    return features_p, labels_p"
      ],
      "id": "d96d430c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d501932e"
      },
      "source": [
        "Utilice la siguiente celda para probar su código:"
      ],
      "id": "d501932e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bad57ca"
      },
      "outputs": [],
      "source": [
        "features_p, labels_p = preprocess(features, labels)"
      ],
      "id": "0bad57ca"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "751cbbea"
      },
      "source": [
        "## **4. Modelamiento**\n",
        "---\n",
        "\n",
        "Para entrenar el modelo, dividimos el conjunto de datos en las particiones de entrenamiento y prueba:"
      ],
      "id": "751cbbea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bbf5001"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "        features_p, labels_p, stratify=labels_p, test_size=0.3\n",
        "        )"
      ],
      "id": "7bbf5001"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce470163"
      },
      "source": [
        "Para el modelo necesitamos optimizar una función de pérdida conocida como la entropía binaria cruzada':\n",
        "\n",
        "$$\n",
        "\\mathcal{L} = - \\frac{1}{N} \\sum_{i=1} ^ N y_i \\log{\\tilde{y}_i} + (1 - y_i) \\log{(1 - \\tilde{y}_i)}\n",
        "$$\n",
        "\n",
        "Debe implementar esta función:"
      ],
      "id": "ce470163"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d666ed1"
      },
      "outputs": [],
      "source": [
        "def binary_crossentropy(y: ArrayLike, y_pred: ArrayLike) -> ArrayLike:\n",
        "\n",
        "    y = np.array(y)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    loss = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
        "\n",
        "    return loss"
      ],
      "id": "5d666ed1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef486652"
      },
      "source": [
        "Utilice las siguientes celdas para probar su código:"
      ],
      "id": "ef486652"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a090bcad"
      },
      "outputs": [],
      "source": [
        "y = np.array([0., 0])\n",
        "y_pred = np.array([0.01, 0.01])\n",
        "# Debe dar un valor bajo al ser valores parecidos\n",
        "print(binary_crossentropy(y, y_pred))"
      ],
      "id": "a090bcad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8e445fc"
      },
      "outputs": [],
      "source": [
        "y = np.array([1., 1.])\n",
        "y_pred = np.array([0.99, 0.99])\n",
        "# Debe dar un valor bajo al ser valores parecidos\n",
        "print(binary_crossentropy(y, y_pred))"
      ],
      "id": "b8e445fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21d44e96"
      },
      "outputs": [],
      "source": [
        "y = np.array([0., 0.])\n",
        "y_pred = np.array([0.99, 0.99])\n",
        "# Debe dar un valor alto al ser valores distintos\n",
        "print(binary_crossentropy(y, y_pred))"
      ],
      "id": "21d44e96"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efb91173"
      },
      "outputs": [],
      "source": [
        "y = np.array([1., 1.])\n",
        "y_pred = np.array([0.01, 0.01])\n",
        "# Debe dar un valor alto al ser valores distintos\n",
        "print(binary_crossentropy(y, y_pred))"
      ],
      "id": "efb91173"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c304a21b"
      },
      "source": [
        "Ahora, debe implementar un modelo de regresión logistica:\n",
        "\n",
        "$$\n",
        "\\tilde{\\mathbf{y}} = \\frac{1}{1 + e^{\\mathbf{X}\\cdot\\mathbf{w}}}\n",
        "$$\n",
        "\n",
        "Donde $\\mathbf{X}$ corresponde a la matriz de características de entrenamiento, $\\mathbf{w}$ es el vector de parámetros y $\\tilde{\\mathbf{y}}$ es la estimación del modelo.\n",
        "\n",
        "> **Nota**: recuerde agregar una columna de unos para considerar el intercepto. El entrenamiento del modelo debe realizarse optimizando la entropía binaria cruzada, puede utilizar la función `optimize` de `scipy` para esto."
      ],
      "id": "c304a21b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20cf0b18"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(BaseEstimator, ClassifierMixin):\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X: ArrayLike, y: ArrayLike) -> \"LogisticRegression\":\n",
        "\n",
        "        intercept = np.ones((X.shape[0], 1))\n",
        "        np.concatenate((intercept, X), axis=1)\n",
        "        self.w = np.zeros(X.shape[1])\n",
        "\n",
        "        loss_fn = lambda w: binary_crossentropy(y, self.sigmoid(np.dot(X, w)))\n",
        "\n",
        "        self.w = optimize.minimize(loss_fn, self.w).x\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X: ArrayLike) -> ArrayLike:\n",
        "\n",
        "        probs = self.sigmoid(np.dot(X, self.w))\n",
        "        return np.vstack([1 - probs, probs]).T\n",
        "\n",
        "    def predict(self, X: ArrayLike) -> ArrayLike:\n",
        "\n",
        "        y_pred = (self.predict_proba(X)[:, 1] >= 0.5).astype(int)\n",
        "        return y_pred"
      ],
      "id": "20cf0b18"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84059c25"
      },
      "source": [
        "Entrenamos el modelo:"
      ],
      "id": "84059c25"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dad2ab6"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression().fit(features_train, labels_train)"
      ],
      "id": "1dad2ab6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "139d1441"
      },
      "source": [
        "## **5. Evaluación**\n",
        "---\n",
        "\n",
        "Obtenga las predicciones del modelo:"
      ],
      "id": "139d1441"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc1f66a2"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(features_test)\n",
        "print(y_pred)"
      ],
      "id": "bc1f66a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64e0be50"
      },
      "source": [
        "- ¿Cuánto da el accuracy del modelo?"
      ],
      "id": "64e0be50"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86c0bbfa"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(labels_test, y_pred)\n",
        "print(accuracy)"
      ],
      "id": "86c0bbfa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53367bdc"
      },
      "source": [
        "- ¿Cuánto da la precisión del modelo?"
      ],
      "id": "53367bdc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5def659"
      },
      "outputs": [],
      "source": [
        "print(precision_score(labels_test,y_pred))"
      ],
      "id": "e5def659"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99c44348"
      },
      "source": [
        "- ¿Cuánto da el recall del modelo?"
      ],
      "id": "99c44348"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34d8ac71"
      },
      "outputs": [],
      "source": [
        "recall = recall_score(labels_test, y_pred)\n",
        "print(recall)"
      ],
      "id": "34d8ac71"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41d05473"
      },
      "source": [
        "- ¿Cuánto da el f1 del modelo?"
      ],
      "id": "41d05473"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7380686a"
      },
      "outputs": [],
      "source": [
        "print(f1_score(labels_test, y_pred))"
      ],
      "id": "7380686a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29075142"
      },
      "source": [
        "- ¿Qué puede concluir de las métricas y del modelo?"
      ],
      "id": "29075142"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tbSOHjvla2m"
      },
      "source": [
        "La métrica de **accuracy** es una medida importante para evaluar el rendimiento general de un modelo, ya que indica qué tan precisa es su predicción en términos generales. Sin embargo, si la distribución de las clases es desigual, la precisión no será suficiente para evaluar el rendimiento del modelo, ya que el modelo podría simplemente predecir siempre la clase mayoritaria para lograr una alta precisión, en lugar de hacer predicciones precisas para todas las clases.\n",
        "\n",
        "La métrica de **precision** es especialmente útil cuando los falsos positivos son perjudiciales, ya que indica que el modelo hace muy pocas predicciones falsas positivas.\n",
        "\n",
        "La métrica de **recall** es importante cuando se necesitan detectar la mayoría de los casos positivos, especialmente en casos donde los falsos negativos son perjudiciales.\n",
        "\n",
        "La puntuación F1 es una métrica que combina tanto el recall como la precision, lo que la convierte en una buena opción si se desea equilibrar ambas métricas.\n",
        "\n",
        "En este estudio, se utilizó un modelo de regresión logística que funciona razonablemente bien en el dataset utilizado para evaluar su rendimiento.\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "6tbSOHjvla2m"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "jupytext": {
      "cell_metadata_filter": "-all",
      "formats": "py:percent,ipynb,md",
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}